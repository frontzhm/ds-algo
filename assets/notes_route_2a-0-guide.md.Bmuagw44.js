import{_ as l,c as p,o as i,ae as e}from"./chunks/framework.CRdajAWK.js";const c=JSON.parse('{"title":"吃透数据结构与算法：我的经验之谈，帮你少走80%的弯路","description":"","frontmatter":{},"headers":[],"relativePath":"notes/route/2a-0-guide.md","filePath":"notes/route/2a-0-guide.md"}'),r={name:"notes/route/2a-0-guide.md"};function t(o,a,n,h,s,u){return i(),p("div",null,[...a[0]||(a[0]=[e('<h1 id="吃透数据结构与算法-我的经验之谈-帮你少走80-的弯路" tabindex="-1">吃透数据结构与算法：我的经验之谈，帮你少走80%的弯路 <a class="header-anchor" href="#吃透数据结构与算法-我的经验之谈-帮你少走80-的弯路" aria-label="Permalink to &quot;吃透数据结构与算法：我的经验之谈，帮你少走80%的弯路&quot;">​</a></h1><p>从事开发、刷题这些年，踩过不少数据结构与算法的坑，也见过很多初学者陷入“盲目刷题、越刷越懵”的困境。其实比起死记硬背代码、刷遍海量习题，更重要的是先看透它们的本质——掌握了核心逻辑，再去刷题、应用，才能事半功倍。</p><p><img src="https://blog-huahua.oss-cn-beijing.aliyuncs.com/blog/code/as_guide.png" alt="as_guide.png"></p><p>这篇文章没有复杂难懂的硬核代码，全是我这些年的实战经验总结，核心就两句话，看懂这两句，哪怕不看后面的内容，也能摸清数据结构与算法的学习脉络：</p><p><strong>种种数据结构，皆为数组（顺序存储）和链表（链式存储）的变换；种种算法，皆为穷举（无遗漏）+ 聪明地穷举（无冗余）。</strong></p><p>如果此刻你还似懂非懂，没关系，接下来我用最直白的语言，把这句话拆开揉碎了讲，帮你真正吃透数据结构与算法的核心，避开那些我曾踩过的弯路。</p><h2 id="一、数据结构的本质-增删查改的存储艺术" tabindex="-1">一、数据结构的本质：增删查改的存储艺术 <a class="header-anchor" href="#一、数据结构的本质-增删查改的存储艺术" aria-label="Permalink to &quot;一、数据结构的本质：增删查改的存储艺术&quot;">​</a></h2><p>很多初学者一看到“数据结构”，就会想到哈希表、栈、队列、树、图这些五花八门的概念，越看越胆怯，觉得内容繁杂、难以掌握。但其实，所有数据结构的底层存储方式，从来都只有两种：<strong>数组（顺序存储）</strong> 和 <strong>链表（链式存储）</strong>。</p><p>那些看似复杂的数据结构，不过是在这两种基础存储方式上，封装了不同的操作API，适配不同的应用场景——它们是上层建筑，而数组和链表，才是最根本的结构基础。我们可以逐一拆解来看：</p><h3 id="_1-数组-顺序存储-紧凑高效的基础载体" tabindex="-1">1. 数组（顺序存储）：紧凑高效的基础载体 <a class="header-anchor" href="#_1-数组-顺序存储-紧凑高效的基础载体" aria-label="Permalink to &quot;1. 数组（顺序存储）：紧凑高效的基础载体&quot;">​</a></h3><p>数组是将元素紧凑连续地存储在一块内存空间中，核心优势是<strong>支持随机访问</strong>，通过索引就能快速定位到目标元素，且存储空间相对节省。但它也有明显短板：扩容时需要重新分配内存、复制数据，时间复杂度O(N)；在中间插入或删除元素时，需要搬移后续所有元素，时间复杂度也为O(N)。</p><p>由数组衍生出的常用数据结构有：</p><ul><li><p>动态数组（ArrayList / Vector）：解决数组固定长度的痛点，自动扩容；</p></li><li><p>字符串：本质是字符数组，额外增加了字符串相关的操作（如拼接、截取）；</p></li><li><p>哈希表（HashMap / 字典）：通过散列函数将键映射到数组，解决散列冲突时，拉链法需结合链表，线性探查法依赖数组特性；</p></li><li><p>位图 / 布隆过滤器：基于数组的二进制位操作，高效解决判重、查询问题；</p></li><li><p>矩阵：二维数组，用于存储多维数据（如我们之前刷过的矩阵第k小元素问题）；</p></li><li><p>栈 / 队列：可通过数组实现（栈用数组尾部操作，队列需处理首尾指针，或用循环数组优化）。</p></li></ul><h3 id="_2-链表-链式存储-灵活高效的连接方式" tabindex="-1">2. 链表（链式存储）：灵活高效的连接方式 <a class="header-anchor" href="#_2-链表-链式存储-灵活高效的连接方式" aria-label="Permalink to &quot;2. 链表（链式存储）：灵活高效的连接方式&quot;">​</a></h3><p>链表是通过指针将离散的元素串联起来，元素不连续存储，核心优势是<strong>插入、删除高效</strong>，只要找到目标节点的前驱/后继，操作指针即可完成，时间复杂度O(1)，且无需担心扩容问题。但短板也很明显：无法随机访问，只能从头遍历，且每个节点需存储指针，消耗更多内存。</p><p>由链表衍生出的常用数据结构有：</p><ul><li><p>基础链表：单链表、双链表、循环链表（适配不同的遍历、操作需求）；</p></li><li><p>跳表：给链表增加索引层，优化查询效率，时间复杂度接近O(logN)；</p></li><li><p>各类树结构：二叉树（满二叉树、完全二叉树）、二叉搜索树（BST）、平衡树（AVL、红黑树）、多叉树（Trie、堆、线段树、并查集）——其中堆是完全二叉树，可用数组实现，其他树多依赖链表存储节点关系；</p></li><li><p>图结构：邻接表（本质是链表数组）、邻接矩阵（二维数组），分别适配稀疏图、稠密图的存储与查询需求。</p></li></ul><h3 id="数据结构的核心-遍历与访问" tabindex="-1">数据结构的核心：遍历与访问 <a class="header-anchor" href="#数据结构的核心-遍历与访问" aria-label="Permalink to &quot;数据结构的核心：遍历与访问&quot;">​</a></h3><p>不管是哪种数据结构，其核心价值都是“高效地处理数据”，而处理数据的基础，就是<strong>遍历 + 访问</strong>，再具体一点，就是增、删、查、改这四种基本操作。</p><p>所有数据结构的设计，都是为了在特定场景下，让这四种操作的效率最大化——比如哈希表优化查询、红黑树保证插入/查询的均衡效率、栈/队列限制操作顺序。</p><p>而遍历与访问的逻辑，其实只有两种框架：线性迭代（for/while）和非线性递归，掌握这两种框架，就能应对所有数据结构的遍历问题：</p><ul><li><p>线性迭代：适用于数组、队列、栈等线性结构，比如数组的for循环遍历、链表的迭代遍历；</p></li><li><p>非线性递归：适用于树、图等非线性结构，比如二叉树的前中后序遍历、N叉树的递归遍历、图的DFS遍历（本质是递归/栈模拟递归）。</p></li></ul><p>甚至可以说，树的遍历是所有非线性遍历的基础，图的遍历不过是树的遍历加上“环的判断”（用visited数组标记），掌握了二叉树的遍历框架，再学图的遍历就会得心应手。</p><h2 id="二、算法的本质-穷举-以及如何聪明地穷举" tabindex="-1">二、算法的本质：穷举，以及如何聪明地穷举 <a class="header-anchor" href="#二、算法的本质-穷举-以及如何聪明地穷举" aria-label="Permalink to &quot;二、算法的本质：穷举，以及如何聪明地穷举&quot;">​</a></h2><p>很多人觉得算法很高大上，是“天才的灵感产物”，但其实对我们刷题、面试中遇到的“计算机算法”（区别于算法工程师的“数学算法”）来说，<strong>本质就是穷举</strong>。</p><p>计算机的核心优势就是“快”，CPU每秒能执行亿万次操作，它解决问题的思路从来都不复杂——把所有可能的解都列出来，再找到符合要求的答案。我们之所以觉得算法难，不是因为穷举本身难，而是难在“无遗漏地穷举”和“无冗余地穷举”。</p><h3 id="先明确-两种算法的区别" tabindex="-1">先明确：两种算法的区别 <a class="header-anchor" href="#先明确-两种算法的区别" aria-label="Permalink to &quot;先明确：两种算法的区别&quot;">​</a></h3><p>这里要特别区分一下，避免初学者误解：</p><ul><li><p>计算机算法（刷题/面试）：核心是“计算机思维”，抽象实际问题，用数据结构和穷举逻辑解决，不需要高深的数学基础；</p></li><li><p>数学算法（算法工程师）：核心是数学建模、调参，依赖概率、统计、线性代数等知识，和我们日常刷题的算法不是一回事。</p></li></ul><p>我们重点讨论的，是前者——这类算法不需要你推导复杂的数学公式，只要掌握“穷举的逻辑”，就能解决80%以上的刷题面试题。</p><h3 id="穷举的第一个关键-无遗漏" tabindex="-1">穷举的第一个关键：无遗漏 <a class="header-anchor" href="#穷举的第一个关键-无遗漏" aria-label="Permalink to &quot;穷举的第一个关键：无遗漏&quot;">​</a></h3><p>遗漏，就意味着答案出错——比如让你找数组的最小值，你穷举时漏掉了那个最小元素，结果自然不正确。而无遗漏的核心，就是<strong>掌握算法框架</strong>，把问题抽象成可遍历的结构（比如树、数组、图），再用固定框架遍历所有可能解。</p><p>难点在“无遗漏”的算法，主要是递归类问题，核心是把问题抽象成“多叉树遍历”：</p><ul><li><p>回溯算法：全排列、子集、组合、N皇后、解数独等问题，本质都是遍历多叉树，收集所有符合条件的路径，核心是“回溯”（撤销选择，避免重复）；</p></li><li><p>动态规划：背包问题、最长子序列、子串问题等，本质是“分解问题+穷举子问题”，核心是找到状态转移方程，无遗漏地遍历所有子问题的解；</p></li><li><p>DFS / BFS：图的遍历、树的遍历、路径问题等，DFS是递归遍历（深度优先），BFS是层序遍历（广度优先），两种方式都能保证无遗漏地遍历所有节点；</p></li><li><p>暴力枚举：最基础的穷举方式，适用于数据量小的场景，直接枚举所有可能解。</p></li></ul><p>这里分享一个小技巧：遇到递归类问题，先想“如何把问题抽象成树”，再用“遍历树”的思路写代码，就能保证无遗漏——比如全排列问题，每一步选择一个元素，就是树的一个分支，遍历所有分支，就能得到所有排列。</p><h3 id="穷举的第二个关键-无冗余" tabindex="-1">穷举的第二个关键：无冗余 <a class="header-anchor" href="#穷举的第二个关键-无冗余" aria-label="Permalink to &quot;穷举的第二个关键：无冗余&quot;">​</a></h3><p>冗余，就意味着效率低下——比如你把相同的计算流程重复执行十次，算法的运行速度就会慢十倍，很可能超过判题平台的时间限制。而无冗余的核心，就是<strong>充分利用已有信息</strong>，避免重复计算、重复遍历。</p><p>难点在“无冗余”的算法，主要是各类优化技巧，核心是“用空间换时间”或“利用问题特性剪枝”：</p><ul><li><p>二分查找：适用于有序数组，利用“有序”特性，每次排除一半不符合条件的元素，把线性遍历的O(N)优化到O(logN)；</p></li><li><p>滑动窗口：适用于子串、子数组问题，用双指针维护一个窗口，避免嵌套循环的重复遍历，把O(N²)优化到O(N)；</p></li><li><p>贪心算法：适用于有“贪心选择性质”的问题（比如活动选择、区间覆盖），不需要穷举所有解，只需每次选择当前最优解，就能得到全局最优解；</p></li><li><p>分治：归并排序、快速排序、大数乘法等，核心是“分而治之”，把大问题拆成小问题，避免重复计算；</p></li><li><p>剪枝：回溯、DFS中，提前排除不可能的分支（比如某条路径已经不符合条件，就不再继续遍历），减少冗余；</p></li><li><p>记忆化搜索：动态规划的雏形，用备忘录存储已经计算过的子问题结果，避免重复计算；</p></li><li><p>并查集：适用于连通性问题、最小生成树，用数组模拟树结构，把连通性判断、合并操作的效率优化到接近O(1)；</p></li><li><p>拓扑排序：适用于有向无环图（DAG）的依赖问题，利用“入度”信息，避免无效遍历。</p></li></ul><h2 id="三、我的学习心法-少刷题-多悟本质" tabindex="-1">三、我的学习心法：少刷题，多悟本质 <a class="header-anchor" href="#三、我的学习心法-少刷题-多悟本质" aria-label="Permalink to &quot;三、我的学习心法：少刷题，多悟本质&quot;">​</a></h2><p>很多初学者的误区是“盲目刷题”——力扣上两千多道题，刷了几百道还是不会，遇到新题依然无从下手。其实刷题的核心不是“数量”，而是“质量”，刷一道题，就要吃透一道题背后的本质，做到“刷一道题，会一类题”。</p><p>结合我自己的学习经验，分享三个最实用的技巧，帮你少走弯路：</p><h3 id="_1-先搭框架-再填细节" tabindex="-1">1. 先搭框架，再填细节 <a class="header-anchor" href="#_1-先搭框架-再填细节" aria-label="Permalink to &quot;1. 先搭框架，再填细节&quot;">​</a></h3><p>不管是数据结构还是算法，先掌握核心框架，再补充细节。比如：</p><ul><li><p>数据结构：先吃透数组和链表的遍历、操作，再学衍生的数据结构（哈希表、树、图），搞懂它们是如何基于数组/链表实现的；</p></li><li><p>算法：先掌握回溯、DP、DFS/BFS、二分、滑动窗口这几个核心框架，遇到新题，先判断“属于哪种框架”，再往框架里填具体逻辑。</p></li></ul><p>比如我们之前刷的“矩阵第k小元素”问题，先判断是“多路归并”问题，核心是“穷举每行的元素，找最小值”，再选择用小顶堆（优先队列）实现“聪明的穷举”，避免冗余，这样思路就清晰了。</p><h3 id="_2-拒绝死记硬背-多问-为什么" tabindex="-1">2. 拒绝死记硬背，多问“为什么” <a class="header-anchor" href="#_2-拒绝死记硬背-多问-为什么" aria-label="Permalink to &quot;2. 拒绝死记硬背，多问“为什么”&quot;">​</a></h3><p>不要死记硬背代码，比如背二分查找的模板、背回溯的代码，而是要多问自己：</p><ul><li><p>这个算法为什么能解决这个问题？它利用了什么问题特性？</p></li><li><p>它是如何做到“无遗漏”的？又是如何“无冗余”的？</p></li><li><p>如果换一种场景，这个算法还能用吗？比如二分查找，除了有序数组，还能用到旋转数组、山脉数组吗？</p></li></ul><p>比如我们手写优先队列时，不要只记“上浮、下沉”的代码，而是要想：上浮是为了维护堆的性质（让优先级高的元素到堆顶），下沉是为了出队后重新维护堆结构，compareFn的作用是自定义优先级——想通了这些，不管是小顶堆还是大顶堆，都能轻松写出。</p><h3 id="_3-多复盘-多总结" tabindex="-1">3. 多复盘，多总结 <a class="header-anchor" href="#_3-多复盘-多总结" aria-label="Permalink to &quot;3. 多复盘，多总结&quot;">​</a></h3><p>刷题不是“刷完就忘”，而是要定期复盘，总结同类题的规律。比如：</p><ul><li><p>子串、子数组问题，大概率能用滑动窗口或前缀和；</p></li><li><p>求最值、方案数，大概率能用动态规划或贪心；</p></li><li><p>连通性、分组问题，大概率能用并查集；</p></li><li><p>路径、遍历问题，大概率能用DFS/BFS。</p></li></ul><p>总结的过程，就是“提炼本质”的过程——把不同题目的“表象”去掉，留下“核心逻辑”，久而久之，你就能一眼看穿题目背后的算法框架，做到“举一反三”。</p><h2 id="最后-算法不难-重在悟" tabindex="-1">最后：算法不难，重在悟 <a class="header-anchor" href="#最后-算法不难-重在悟" aria-label="Permalink to &quot;最后：算法不难，重在悟&quot;">​</a></h2><p>我刚开始学数据结构与算法时，也和很多人一样，觉得难、觉得抽象，刷一道题要卡很久，甚至怀疑自己是不是不适合学。但后来慢慢发现，只要跳出“死记硬背”的误区，抓住“数组+链表”和“穷举”这两个核心，一切都会变得简单。</p><p>数据结构没有那么多花里胡哨的东西，本质就是两种存储方式的变换；算法也没有那么多高深莫测的技巧，本质就是无遗漏、无冗余的穷举。</p><p>希望这篇经验之谈，能帮你避开我曾踩过的弯路，更透彻地理解数据结构与算法。记住：学习算法，不是为了刷题而刷题，而是为了培养“计算机思维”——学会用计算机的方式思考问题，学会用合理的数据结构和算法，高效地解决问题。</p><p>授人以鱼不如授人以渔，愿你在学习算法的路上，少走弯路，多有收获，最终能享受支配算法的乐趣，而不是被算法支配。</p>',59)])])}const _=l(r,[["render",t]]);export{c as __pageData,_ as default};
